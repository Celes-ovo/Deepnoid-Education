{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN_VGG_Build.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pulsar-kkaturi/Deepnoid-Education/blob/master/notebooks/CNN_VGG_Build.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fsLexN5mWmf"
      },
      "source": [
        "# NEURAL NETWORK BUILD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ-lxCOpmWmj"
      },
      "source": [
        "# 1. LIbrary Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMUn1R-5mWmj"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "import pandas as pd\n",
        "import csv\n",
        "import shutil\n",
        "import json\n",
        "from sklearn import metrics as skmet\n",
        "from skimage import morphology\n",
        "from skimage import measure\n",
        "from skimage import exposure\n",
        "\n",
        "### Tensorflow 2.0 ###\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyxOHppVmWmk"
      },
      "source": [
        "# 2. Module Fuction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9nTwrpImWmk"
      },
      "source": [
        "* keras application VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw7cnbF6mWmk",
        "outputId": "52fb543f-d942-4b79-e669-957618f433bc"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JQNlRBPmWml"
      },
      "source": [
        "* Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PsFuh3pmWml"
      },
      "source": [
        "class ConvBlock:\n",
        "    def conv_block_2d(self, lr_conv, lr_num, par_list):\n",
        "        # parameter\n",
        "        conv_size = par_list[0]\n",
        "        conv_str = par_list[1]\n",
        "        conv_act = par_list[2]\n",
        "        pool_str = par_list[3]\n",
        "        reg_weight = None\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv2D(conv_size, conv_str, activation=conv_act, padding='same', \n",
        "                                    kernel_initializer='he_normal')(lr_conv)\n",
        "        lr_batn = layers.BatchNormalization(axis=-1)(lr_conv)\n",
        "        lr_pool = layers.MaxPooling2D(pool_size=pool_str)(lr_batn)\n",
        "        return lr_pool\n",
        "    def conv_block_3d(self, lr_input, lr_num, par_list):\n",
        "        # parameter\n",
        "        conv_size = par_list[0]\n",
        "        conv_str = par_list[1]\n",
        "        conv_act = par_list[2]\n",
        "        pool_str = par_list[3]\n",
        "        drop_rate = par_list[4]\n",
        "        # code\n",
        "        for i in range(lr_num):\n",
        "            lr_conv = layers.Conv3D(conv_size, conv_str, activation=conv_act,\n",
        "                                    padding='same', kernel_initializer='he_normal')(lr_input)\n",
        "        lr_batn = layers.BatchNormalization(axis=-1)(lr_conv)\n",
        "        lr_pool = layers.MaxPooling3D(pool_size=(pool_str, pool_str, pool_str))(lr_batn)\n",
        "        return lr_pool\n",
        "    def output_block(self, lr_dense, block_num, flat_count, reg_weight, act_func, drop_rate):\n",
        "        lr_dense = layers.Flatten()(lr_dense)\n",
        "        lr_dense = layers.Dropout(drop_rate)(lr_dense)\n",
        "        for i in range(block_num):\n",
        "            lr_dense = layers.Dense(flat_count[i], kernel_regularizer=reg_weight,\n",
        "                                    activation=act_func)(lr_dense)\n",
        "#             lr_dense = layers.BatchNormalization(axis=-1)(lr_dense)\n",
        "#             lr_dense = layers.Activation(act_func)(lr_dense)\n",
        "            lr_dense = layers.Dropout(drop_rate)(lr_dense)\n",
        "        return lr_dense\n",
        "    \n",
        "cn = ConvBlock()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nkrFK5jmWmm"
      },
      "source": [
        "def VGG16_2D(par_dic):\n",
        "    # parameters\n",
        "    input_size = par_dic['input_size']\n",
        "    drop_out = par_dic['drop_out']\n",
        "    reg_weight = par_dic['reg_weight']\n",
        "    flat_count = par_dic['flat_count']\n",
        "    class_count = par_dic['class_count']\n",
        "    conv_act = par_dic['conv_act']\n",
        "    flat_act = par_dic['flat_act']\n",
        "    output_act = par_dic['output_act']\n",
        "    conv_str = par_dic['conv_str']\n",
        "    pool_str = par_dic['pool_str']\n",
        "    dens_num = par_dic['dens_num']\n",
        "\n",
        "    # code block\n",
        "    inputs = Input(shape=(input_size, input_size, 1))\n",
        "    block1 = cn.conv_block_2d(inputs, 2, [64, conv_str, conv_act, pool_str, reg_weight])\n",
        "    block2 = cn.conv_block_2d(block1, 2, [128, conv_str, conv_act, pool_str, reg_weight])\n",
        "    block3 = cn.conv_block_2d(block2, 3, [256, conv_str, conv_act, pool_str, reg_weight])\n",
        "    block4 = cn.conv_block_2d(block3, 3, [512, conv_str, conv_act, pool_str, reg_weight])\n",
        "    block5 = cn.conv_block_2d(block4, 3, [512, conv_str, conv_act, pool_str, reg_weight])\n",
        "    dens = cn.output_block(block5, dens_num, flat_count, reg_weight, flat_act, drop_out)\n",
        "    outputs = layers.Dense(class_count, activation=output_act)(dens)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOi3RDaomWmm"
      },
      "source": [
        "def VGG16_3D(input_size, block_num, drop_out, flat_count, class_count, conv_act, flat_act, output_act,\n",
        "           conv_str, pool_str):\n",
        "\n",
        "    inputs = Input(shape=(input_size, input_size, input_size, 1))\n",
        "    block1 = cn.conv_block_3d(inputs, 2, [64, conv_str, conv_act, pool_str, drop_out])\n",
        "    block2 = cn.conv_block_3d(block1, 2, [128, conv_str, conv_act, pool_str, drop_out])\n",
        "    block3 = cn.conv_block_3d(block2, 3, [256, conv_str, conv_act, pool_str, drop_out])\n",
        "    block4 = cn.conv_block_3d(block3, 3, [512, conv_str, conv_act, pool_str, drop_out])\n",
        "    block5 = cn.conv_block_3d(block4, 3, [512, conv_str, conv_act, pool_str, drop_out])\n",
        "    flat = layers.Flatten()(block5)\n",
        "    drop1 = layers.Dropout(drop_out)(flat)\n",
        "    dens = layers.Dense(flat_count, activation=flat_act)(drop1)\n",
        "    drop2 = layers.Dropout(drop_out)(dens)\n",
        "    outputs = layers.Dense(class_count, activation=output_act)(drop2)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvmjT-BDmWmm"
      },
      "source": [
        "# 3. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h21VXXuImWmm"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test)=keras.datasets.mnist.load_data(path='minist.npz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZhc0G0emWmn",
        "outputId": "d6154e06-b0e2-4d17-85bd-18850fdf40f2"
      },
      "source": [
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7YSw3QkmWmn"
      },
      "source": [
        "# 3.1 2D dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5iscUbymWmn",
        "outputId": "dc31339e-f4e4-4599-f5c8-a84ec2fe518d"
      },
      "source": [
        "x_train_list = []\n",
        "x_test_list = []\n",
        "for i, i_ in enumerate(x_train[:50000]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_train[i]\n",
        "    x_train_list.append(arr)\n",
        "for i, i_ in enumerate(x_test[:5000]):\n",
        "    arr = np.zeros(shape=(32, 32))\n",
        "    arr[:28,:28] = x_test[i]\n",
        "    x_test_list.append(arr)\n",
        "\n",
        "x_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "print(x_train1.shape, x_test1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 1) (5000, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYrbF26lmWmn",
        "outputId": "3facc59f-553a-4dae-d06a-d6b4bd24f5e5"
      },
      "source": [
        "y_train_list = []\n",
        "y_test_list = []\n",
        "for i, i_ in enumerate(y_train[:50000]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_train_list.append(zero)\n",
        "\n",
        "for i, i_ in enumerate(y_test[:5000]):\n",
        "    zero = [0]*10\n",
        "    zero[i_] = 1\n",
        "    y_test_list.append(zero)    \n",
        "    \n",
        "y_train1 = np.array(y_train_list)\n",
        "y_test1 = np.array(y_test_list)\n",
        "print(y_train1.shape, y_test1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10) (5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDbfzKwImWmo",
        "outputId": "bfc9054e-3601-4826-ab27-2ad77704d059"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,i+1)\n",
        "    plt.imshow(x_train1[i][...,0], cmap='gray')\n",
        "    plt.title('Class = {}'.format(y_train[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNvCkU-rmWmo"
      },
      "source": [
        "## 3.2 3D dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7_FSBYamWmo",
        "outputId": "bf4a9bdf-0ad7-4a17-a32b-2925158c8861"
      },
      "source": [
        "x_train_list = []\n",
        "y_train_list = []\n",
        "x_test_list = []\n",
        "y_test_list = []\n",
        "for i in range(1200):\n",
        "    zero = np.zeros(shape=(32,32,32))\n",
        "    ones = np.ones(shape=(16,16,16))\n",
        "    ran = int(np.random.randint(10, size=1)-5)\n",
        "    if 0 <= i < 400:\n",
        "        zero[:,:,:] = (ran*10) + 150\n",
        "        x_train_list.append(zero)\n",
        "        y_train_list.append([1,0,0])\n",
        "    elif 400 <= i < 800:\n",
        "        zero[8+ran:24+ran,8+ran:24+ran,8+ran:24+ran] = (ran*10) + 200\n",
        "        x_train_list.append(zero)\n",
        "        y_train_list.append([0,1,0])\n",
        "    elif 800 <= i < 1200:\n",
        "        for j in range(32):\n",
        "            for k in range(32):\n",
        "                for l in range(32):\n",
        "                    if ((j-16+ran)**2) + ((k-16+ran)**2) + ((l-16+ran)**2) < 100:\n",
        "                        zero[j,k,l] = (ran*10) + 200\n",
        "        x_train_list.append(zero)\n",
        "        y_train_list.append([0,0,1])\n",
        "\n",
        "for i in range(600):\n",
        "    zero = np.zeros(shape=(32,32,32))\n",
        "    ones = np.ones(shape=(16,16,16))\n",
        "    ran = int(np.random.randint(10, size=1)-5)\n",
        "    if 0 <= i < 200:\n",
        "        zero[:,:,:] = (ran*10) + 150\n",
        "        x_test_list.append(zero)\n",
        "        y_test_list.append([1,0,0])\n",
        "    elif 200 <= i < 400:\n",
        "        zero[8+ran:24+ran,8+ran:24+ran,8+ran:24+ran] = (ran*10) + 200\n",
        "        x_test_list.append(zero)\n",
        "        y_test_list.append([0,1,0])\n",
        "    elif 400 <= i < 600:\n",
        "        for j in range(32):\n",
        "            for k in range(32):\n",
        "                for l in range(32):\n",
        "                    if ((j-16+ran)**2) + ((k-16+ran)**2) + ((l-16+ran)**2) < 100:\n",
        "                        zero[j,k,l] = (ran*10) + 200\n",
        "        x_test_list.append(zero)\n",
        "        y_test_list.append([0,0,1])\n",
        "\n",
        "x3_train1 = np.expand_dims(np.array(x_train_list), axis=-1)\n",
        "x3_test1 = np.expand_dims(np.array(x_test_list), axis=-1)\n",
        "y3_train1 = np.array(y_train_list)\n",
        "y3_test1 = np.array(y_test_list)\n",
        "print(x3_train1.shape, x3_test1.shape)\n",
        "print(y3_train1.shape, y3_test1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1200, 32, 32, 32, 1) (600, 32, 32, 32, 1)\n",
            "(1200, 3) (600, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp8apIbbmWmp",
        "outputId": "24902926-5ce3-4f79-cea4-ad69aadc2c92"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        plt.subplot(3,3, (3*i)+j+1)\n",
        "        plt.imshow(x3_train1[(i*400)+(j*100)][(8*j)+8,...,0], cmap='gray')\n",
        "        plt.title('Class = {}'.format(str(y3_train1[(i*400)+(j*100)])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWCfiABkmWmp"
      },
      "source": [
        "# 3. Model Build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck3Ecxs8mWmp"
      },
      "source": [
        "## 3.1 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RyJRUzAmWmp"
      },
      "source": [
        "train_param_set = {'cls_vgg': {'model_name': 'VGG19',\n",
        "                               'array_dim': '2d',\n",
        "                               'split_rate': 0.2,\n",
        "                               'k_fold': 5,\n",
        "                               'aug_rate': {'benign': 4, 'malignant': 4},\n",
        "                               'batch_size': 50,\n",
        "                               'epoch': 100,\n",
        "                               'gpu_vision': '0,1,2,3',\n",
        "                               'loss': losses.CategoricalCrossentropy(),\n",
        "                               'learning_rate': '1e-4',\n",
        "                               'optimizer': optimizers.Adam(lr=1e-4),\n",
        "                               'metric': ['accuracy'],\n",
        "                               'threshold': 0.5,\n",
        "                               'ensemble_mode': 'soft',\n",
        "                               'positive_idx': 0,\n",
        "                               'smode_in': None,\n",
        "                               'smode_out': 'pred',\n",
        "                               'sample_mode': False,\n",
        "                               'step_list': {'hold_out': [1, 2, 3, 4, 5, 6],\n",
        "                                             'k_fold': [1, 2.1, 2.2, 2.3, 2.4, 3, 4, 5]}}}\n",
        "\n",
        "network_param_set = {'vgg': {'input_size': 32,\n",
        "                             'block_num': 1,\n",
        "                             'layer_num': 1,\n",
        "                             'drop_out': 0.5,\n",
        "                             'reg_weight': regularizers.l2(1e-3),\n",
        "                             'dens_num': 2,\n",
        "                             'flat_count': [1000, 500],\n",
        "                             'class_count': 10,\n",
        "                             'conv_act': 'relu',\n",
        "                             'flat_act': 'relu',\n",
        "                             'output_act': 'softmax',\n",
        "                             'conv_str': 3,\n",
        "                             'pool_str': 2}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yRcrJ1-RmWmp",
        "outputId": "425691f5-06b2-4583-aef5-af26b9279575"
      },
      "source": [
        "model = VGG16_2D(network_param_set['vgg'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1000)              513000    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 15,737,934\n",
            "Trainable params: 15,734,990\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJt621_cmWmq"
      },
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=1e-5), metrics=['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iKfz_dDumWmq",
        "outputId": "ffcb850a-e9de-41ab-d56a-23a384f8cebb"
      },
      "source": [
        "callback_list = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),\n",
        "                         keras.callbacks.ModelCheckpoint(filepath=os.path.join('model.h5'),\n",
        "                                                         monitor='val_loss', save_best_only=True),\n",
        "                         keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)]\n",
        "\n",
        "history = model.fit(x_train1, y_train1, epochs=100, batch_size=32, \n",
        "                    validation_data=(x_test1, y_test1),\n",
        "                    callbacks=callback_list, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 5000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 51s 1ms/sample - loss: 3.5326 - acc: 0.3820 - val_loss: 1.8008 - val_acc: 0.8850\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 1.8617 - acc: 0.8287 - val_loss: 1.4910 - val_acc: 0.9482\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 1.5481 - acc: 0.9306 - val_loss: 1.4215 - val_acc: 0.9634\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 1.4347 - acc: 0.9592 - val_loss: 1.3931 - val_acc: 0.9674\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 47s 941us/sample - loss: 1.3635 - acc: 0.9717 - val_loss: 1.3330 - val_acc: 0.9738\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 1.2999 - acc: 0.9795 - val_loss: 1.2826 - val_acc: 0.9758\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 47s 948us/sample - loss: 1.2351 - acc: 0.9850 - val_loss: 1.2537 - val_acc: 0.9754\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 47s 949us/sample - loss: 1.1748 - acc: 0.9888 - val_loss: 1.1875 - val_acc: 0.9798\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 1.1105 - acc: 0.9915 - val_loss: 1.1305 - val_acc: 0.9808\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 47s 943us/sample - loss: 1.0465 - acc: 0.9932 - val_loss: 1.0591 - val_acc: 0.9840\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.9809 - acc: 0.9946 - val_loss: 1.0070 - val_acc: 0.9814\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.9140 - acc: 0.9956 - val_loss: 0.9338 - val_acc: 0.9822\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.8466 - acc: 0.9962 - val_loss: 0.9043 - val_acc: 0.9792\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.7768 - acc: 0.9971 - val_loss: 0.8187 - val_acc: 0.9802\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.7088 - acc: 0.9975 - val_loss: 0.7403 - val_acc: 0.9838\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.6438 - acc: 0.9974 - val_loss: 0.7426 - val_acc: 0.9714\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.5846 - acc: 0.9976 - val_loss: 0.6382 - val_acc: 0.9812\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.5268 - acc: 0.9980 - val_loss: 0.5629 - val_acc: 0.9830\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.4689 - acc: 0.9982 - val_loss: 0.5114 - val_acc: 0.9844\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 47s 941us/sample - loss: 0.4176 - acc: 0.9984 - val_loss: 0.4527 - val_acc: 0.9858\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.3626 - acc: 0.9992 - val_loss: 0.4029 - val_acc: 0.9852\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.3142 - acc: 0.9984 - val_loss: 0.3803 - val_acc: 0.9804\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 0.2707 - acc: 0.9991 - val_loss: 0.3486 - val_acc: 0.9818\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.2335 - acc: 0.9989 - val_loss: 0.2753 - val_acc: 0.9852\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 47s 941us/sample - loss: 0.1984 - acc: 0.9992 - val_loss: 0.2461 - val_acc: 0.9856\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 47s 943us/sample - loss: 0.1669 - acc: 0.9994 - val_loss: 0.2097 - val_acc: 0.9852\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.1401 - acc: 0.9992 - val_loss: 0.2006 - val_acc: 0.9802\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 47s 945us/sample - loss: 0.1190 - acc: 0.9992 - val_loss: 0.1654 - val_acc: 0.9850\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 47s 943us/sample - loss: 0.1014 - acc: 0.9989 - val_loss: 0.1645 - val_acc: 0.9826\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.0851 - acc: 0.9997 - val_loss: 0.1295 - val_acc: 0.9872\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.0735 - acc: 0.9992 - val_loss: 0.1316 - val_acc: 0.9844\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.0629 - acc: 0.9994 - val_loss: 0.1075 - val_acc: 0.9862\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 47s 934us/sample - loss: 0.0514 - acc: 0.9998 - val_loss: 0.1146 - val_acc: 0.9838\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.0421 - acc: 0.9995 - val_loss: 0.1095 - val_acc: 0.9828\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 47s 942us/sample - loss: 0.0351 - acc: 0.9995 - val_loss: 0.0966 - val_acc: 0.9854\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.0307 - acc: 0.9994 - val_loss: 0.0820 - val_acc: 0.9860\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 47s 945us/sample - loss: 0.0248 - acc: 0.9999 - val_loss: 0.0814 - val_acc: 0.9856\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.0223 - acc: 0.9994 - val_loss: 0.0766 - val_acc: 0.9852\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 0.0179 - acc: 0.9998 - val_loss: 0.0694 - val_acc: 0.9870\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 0.0161 - acc: 0.9997 - val_loss: 0.0589 - val_acc: 0.9882\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0143 - acc: 0.9996 - val_loss: 0.0747 - val_acc: 0.9848\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.0119 - acc: 0.9999 - val_loss: 0.0641 - val_acc: 0.9868\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.0114 - acc: 0.9996 - val_loss: 0.0715 - val_acc: 0.9846\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0104 - acc: 0.9996 - val_loss: 0.0724 - val_acc: 0.9860\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.0100 - acc: 0.9996 - val_loss: 0.0687 - val_acc: 0.9854\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.0086 - acc: 0.9998 - val_loss: 0.0701 - val_acc: 0.9858\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0081 - acc: 0.9997 - val_loss: 0.0753 - val_acc: 0.9866\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0079 - acc: 0.9997 - val_loss: 0.0633 - val_acc: 0.9882\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.0075 - acc: 0.9998 - val_loss: 0.0674 - val_acc: 0.9872\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 47s 944us/sample - loss: 0.0074 - acc: 0.9996 - val_loss: 0.0541 - val_acc: 0.9878\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.0068 - acc: 0.9996 - val_loss: 0.0759 - val_acc: 0.9824\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.0067 - acc: 0.9996 - val_loss: 0.0626 - val_acc: 0.9866\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0065 - acc: 0.9997 - val_loss: 0.0610 - val_acc: 0.9866\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 47s 941us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 0.9878\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0063 - acc: 0.9997 - val_loss: 0.0742 - val_acc: 0.9844\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0063 - acc: 0.9997 - val_loss: 0.0610 - val_acc: 0.9860\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.0068 - acc: 0.9996 - val_loss: 0.0663 - val_acc: 0.9864\n",
            "Epoch 58/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.0064 - acc: 0.9995 - val_loss: 0.0615 - val_acc: 0.9876\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.0056 - acc: 0.9998 - val_loss: 0.0704 - val_acc: 0.9860\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 47s 932us/sample - loss: 0.0056 - acc: 0.9998 - val_loss: 0.0687 - val_acc: 0.9858\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.0053 - acc: 0.9998 - val_loss: 0.0700 - val_acc: 0.9856\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 47s 941us/sample - loss: 0.0051 - acc: 0.9998 - val_loss: 0.0994 - val_acc: 0.9802\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.0063 - acc: 0.9995 - val_loss: 0.0615 - val_acc: 0.9874\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 0.0061 - acc: 0.9995 - val_loss: 0.0620 - val_acc: 0.9868\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 0.9872\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0587 - val_acc: 0.9878\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 0.9882\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 0.9884\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9888\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 0.9888\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 47s 944us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9888\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 47s 943us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 0.9888\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 47s 941us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9892\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 47s 941us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0582 - val_acc: 0.9886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYSn7pqmmWmq"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "# Accuracy graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, acc, 'b', label='Training acc = {}%'.format(np.around(np.max(acc) * 100, decimals=1)))\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc = {}%'.format(np.around(np.max(val_acc) * 100, decimals=1)))\n",
        "plt.title('{} Accuracy (Total Epoch = {})'.format('VGG16', len(acc)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()\n",
        "# Loss graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, loss, 'b', label='Training loss = {}'.format(np.around(np.min(loss), decimals=3)))\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss= {}'.format(np.around(np.min(val_loss), decimals=3)))\n",
        "plt.title('{} Loss (Total Epoch = {})'.format('VGG16', len(loss)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVT4KNd5mWmq"
      },
      "source": [
        "## 3.2 3D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Et33FS_1mWmr",
        "outputId": "dba18b01-62b5-4374-83ad-aa595be1d5df"
      },
      "source": [
        "model = VGG16_3D(32, 1, 0.5, 256, 3, 'relu', 'relu', 'softmax', 3, 2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 32, 1)]   0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 32, 32, 32, 64)    1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32, 64)    256       \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 16, 16, 16, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 16, 16, 16, 128)   221312    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 16, 128)   512       \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 8, 8, 8, 128)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_6 (Conv3D)            (None, 8, 8, 8, 256)      884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 8, 256)      1024      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 4, 4, 4, 256)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_9 (Conv3D)            (None, 4, 4, 4, 512)      3539456   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 4, 4, 4, 512)      2048      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 2, 2, 2, 512)      0         \n",
            "_________________________________________________________________\n",
            "conv3d_12 (Conv3D)           (None, 2, 2, 2, 512)      7078400   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 2, 512)      2048      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3 (None, 1, 1, 1, 512)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 11,863,939\n",
            "Trainable params: 11,860,995\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06KnVstxmWmr",
        "outputId": "a6abddb3-7f33-4377-8a34-5089521d4de6"
      },
      "source": [
        "model.compile(loss=losses.CategoricalCrossentropy(), optimizer=optimizers.Adam(lr=1e-5), metrics=['acc'])\n",
        "callback_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=12),\n",
        "                         keras.callbacks.ModelCheckpoint(filepath=os.path.join('model.h5'),\n",
        "                                                         monitor='val_loss', save_best_only=True),\n",
        "                         keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10)]\n",
        "\n",
        "history = model.fit(x3_train1, y3_train1, epochs=100, batch_size=32, \n",
        "                    validation_data=(x3_test1, y3_test1),\n",
        "                    callbacks=callback_list, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1200 samples, validate on 600 samples\n",
            "Epoch 1/100\n",
            "1200/1200 [==============================] - 12s 10ms/sample - loss: 0.7309 - acc: 0.8250 - val_loss: 7.4159 - val_acc: 0.3333\n",
            "Epoch 2/100\n",
            "1200/1200 [==============================] - 7s 6ms/sample - loss: 0.0624 - acc: 0.9767 - val_loss: 2.1473 - val_acc: 0.3917\n",
            "Epoch 3/100\n",
            "1200/1200 [==============================] - 7s 6ms/sample - loss: 0.0446 - acc: 0.9825 - val_loss: 0.1712 - val_acc: 0.9633\n",
            "Epoch 4/100\n",
            "1200/1200 [==============================] - 7s 6ms/sample - loss: 0.0224 - acc: 0.9950 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "1200/1200 [==============================] - 7s 6ms/sample - loss: 0.0159 - acc: 0.9975 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "1024/1200 [========================>.....] - ETA: 0s - loss: 0.0092 - acc: 0.9990WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
            "1024/1200 [========================>.....] - ETA: 0s - loss: 0.0092 - acc: 0.9990"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-181a4e7bc910>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m history = model.fit(x3_train1, y3_train1, epochs=100, batch_size=32, \n\u001b[0;32m      8\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3_test1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my3_test1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                     callbacks=callback_list, shuffle=True)\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32m~\\Anaconda3\\envs\\py37_gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK_aCtLrmWmr"
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(acc))\n",
        "# Accuracy graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, acc, 'b', label='Training acc = {}%'.format(np.around(np.max(acc) * 100, decimals=1)))\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc = {}%'.format(np.around(np.max(val_acc) * 100, decimals=1)))\n",
        "plt.title('{} Accuracy (Total Epoch = {})'.format('VGG16', len(acc)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()\n",
        "# Loss graph\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.plot(epochs, loss, 'b', label='Training loss = {}'.format(np.around(np.min(loss), decimals=3)))\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss= {}'.format(np.around(np.min(val_loss), decimals=3)))\n",
        "plt.title('{} Loss (Total Epoch = {})'.format('VGG16', len(loss)), fontsize=15, y=1.02)\n",
        "plt.xticks(size=15)\n",
        "plt.yticks(size=15)\n",
        "plt.legend(fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26qBMmXXmWmr"
      },
      "source": [
        "# 4. Additional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8_uGVPnmWmr"
      },
      "source": [
        "# 4.1 VGG19"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j2tjkknmWmr"
      },
      "source": [
        "* keras application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWjw1sw8mWmr"
      },
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "model = VGG19(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9hdqn2wmWmr"
      },
      "source": [
        "def VGG19_2D(input_size, drop_out, flat_count, class_count, conv_act, flat_act, output_act, conv_str, pool_str):\n",
        "\n",
        "    inputs = Input(shape=(input_size, input_size, 1))\n",
        "    block1 = cn.conv_block_2d(inputs, 2, [64, conv_str, conv_act, pool_str, drop_out])\n",
        "    block2 = cn.conv_block_2d(block1, 2, [128, conv_str, conv_act, pool_str, drop_out])\n",
        "    block3 = cn.conv_block_2d(block2, 4, [256, conv_str, conv_act, pool_str, drop_out])\n",
        "    block4 = cn.conv_block_2d(block3, 4, [512, conv_str, conv_act, pool_str, drop_out])\n",
        "    block5 = cn.conv_block_2d(block4, 4, [512, conv_str, conv_act, pool_str, drop_out])\n",
        "    flat = layers.Flatten()(block5)\n",
        "    drop1 = layers.Dropout(drop_out)(flat)\n",
        "    dens = layers.Dense(flat_count, activation=flat_act)(drop1)\n",
        "    drop2 = layers.Dropout(drop_out)(dens)\n",
        "    outputs = layers.Dense(class_count, activation=output_act)(drop2)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = VGG19_2D(32, 0.5, 256, 2, 'relu', 'relu', 'sigmoid', 3, 2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm27XS59mWms"
      },
      "source": [
        "def VGGfree_2D(input_size, block_num, layer_num, drop_out, flat_count, class_count, conv_act, flat_act, output_act, conv_str, pool_str):\n",
        "\n",
        "    inputs = Input(shape=(input_size, input_size, 1))\n",
        "    block = layers.Conv2D(32, conv_str, activation=conv_act, padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    for i in range(block_num):\n",
        "        block = cn.conv_block_2d(block, layer_num, [32*(2**i), conv_str, conv_act, pool_str, drop_out])\n",
        "    flat = layers.Flatten()(block)\n",
        "    drop1 = layers.Dropout(drop_out)(flat)\n",
        "    dens = layers.Dense(flat_count, activation=flat_act)(drop1)\n",
        "    drop2 = layers.Dropout(drop_out)(dens)\n",
        "    outputs = layers.Dense(class_count, activation=output_act)(drop2)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = VGGfree_2D(32, 5, 2, 0.5, 256, 2, 'relu', 'relu', 'sigmoid', 3, 2)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mtaCfqFmWms"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}